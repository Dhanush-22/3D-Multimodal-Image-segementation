{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-28T13:28:49.512147Z",
     "iopub.status.busy": "2023-03-28T13:28:49.510871Z",
     "iopub.status.idle": "2023-03-28T13:28:49.524635Z",
     "shell.execute_reply": "2023-03-28T13:28:49.523461Z",
     "shell.execute_reply.started": "2023-03-28T13:28:49.512096Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import metrics\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum, concatenate\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D\n",
    "# from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "# from medpy.io import load\n",
    "import numpy as np\n",
    "\n",
    "#import cv2\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:28:50.821594Z",
     "iopub.status.busy": "2023-03-28T13:28:50.820223Z",
     "iopub.status.idle": "2023-03-28T13:28:50.839434Z",
     "shell.execute_reply": "2023-03-28T13:28:50.838131Z",
     "shell.execute_reply.started": "2023-03-28T13:28:50.821525Z"
    }
   },
   "outputs": [],
   "source": [
    "# dice loss as defined above for 4 classes\n",
    "# The smooth parameter is added to avoid division by zero error and to stabilize the loss calculation.\n",
    "# def dice_coef(y_true, y_pred, smooth=1):\n",
    "#     class_num = 4\n",
    "#     for i in range(class_num):\n",
    "#         y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "#         y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "#         intersection = K.sum(y_true_f * y_pred_f)\n",
    "#         loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "#         if i == 0:\n",
    "#             total_loss = loss\n",
    "#         else:\n",
    "#             total_loss = total_loss + loss\n",
    "#     total_loss = total_loss / class_num\n",
    "#     return total_loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2,3)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=0.000001):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=0.000001):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=0.000001):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision\n",
    "# Precision: TP / (TP + FP)\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity  \n",
    "# Sensitivity or recall: TP / (TP + FN)\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "# Specificity: TN / (TN + FP)\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:28:51.941423Z",
     "iopub.status.busy": "2023-03-28T13:28:51.941004Z",
     "iopub.status.idle": "2023-03-28T13:28:51.949686Z",
     "shell.execute_reply": "2023-03-28T13:28:51.947215Z",
     "shell.execute_reply.started": "2023-03-28T13:28:51.941384Z"
    }
   },
   "outputs": [],
   "source": [
    "#  c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(s)\n",
    "#     c1 = Dropout(0.1)(c1)\n",
    "#     c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c1)\n",
    "#     p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "#     c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p1)\n",
    "#     c2 = Dropout(0.1)(c2)\n",
    "#     c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c2)\n",
    "#     p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "     \n",
    "#     c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p2)\n",
    "#     c3 = Dropout(0.2)(c3)\n",
    "#     c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c3)\n",
    "#     p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "     \n",
    "#     c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p3)\n",
    "#     c4 = Dropout(0.2)(c4)\n",
    "#     c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c4)\n",
    "#     p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n",
    "     \n",
    "#     c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(p4)\n",
    "#     c5 = Dropout(0.3)(c5)\n",
    "#     c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c5)\n",
    "    \n",
    "#     #Expansive path \n",
    "#     u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "#     u6 = concatenate([u6, c4])\n",
    "#     c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u6)\n",
    "#     c6 = Dropout(0.2)(c6)\n",
    "#     c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c6)\n",
    "     \n",
    "#     u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "#     u7 = concatenate([u7, c3])\n",
    "#     c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u7)\n",
    "#     c7 = Dropout(0.2)(c7)\n",
    "#     c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c7)\n",
    "     \n",
    "#     u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "#     u8 = concatenate([u8, c2])\n",
    "#     c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u8)\n",
    "#     c8 = Dropout(0.1)(c8)\n",
    "#     c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c8)\n",
    "     \n",
    "#     u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "#     u9 = concatenate([u9, c1])\n",
    "#     c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(u9)\n",
    "#     c9 = Dropout(0.1)(c9)\n",
    "#     c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=ker_init, padding='same')(c9)\n",
    "     \n",
    "#     outputs = Conv3D(4, (1, 1, 1), activation='softmax')(c9)\n",
    "     \n",
    "#     model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:29:49.879240Z",
     "iopub.status.busy": "2023-03-28T13:29:49.878826Z",
     "iopub.status.idle": "2023-03-28T13:29:49.903666Z",
     "shell.execute_reply": "2023-03-28T13:29:49.902263Z",
     "shell.execute_reply.started": "2023-03-28T13:29:49.879199Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(input_mat,num_filters,kernel_size,batch_norm):\n",
    "  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(input_mat)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    "  \n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(X)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    "  \n",
    "  X = Activation('relu')(X)\n",
    "  \n",
    "  return X\n",
    "\n",
    "\n",
    "# def Unet_3d(input_img, n_filters = 16, dropout = 0.2, batch_norm = True):\n",
    "\n",
    "#   c1 = conv_block(input_img,n_filters,3,batch_norm)\n",
    "#   p1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(c1)\n",
    "#   p1 = Dropout(dropout)(p1)\n",
    "  \n",
    "#   c2 = conv_block(p1,n_filters*2,3,batch_norm);\n",
    "#   p2 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c2)\n",
    "#   p2 = Dropout(dropout)(p2)\n",
    "\n",
    "#   c3 = conv_block(p2,n_filters*4,3,batch_norm);\n",
    "#   p3 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c3)\n",
    "#   p3 = Dropout(dropout)(p3)\n",
    "  \n",
    "#   c4 = conv_block(p3,n_filters*8,3,batch_norm);\n",
    "#   p4 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c4)\n",
    "#   p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "#   c5 = conv_block(p4,n_filters*16,3,batch_norm);\n",
    "#   p5 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c5)\n",
    "#   p5 = Dropout(dropout)(p5)\n",
    "  \n",
    "#   c55 = conv_block(p5,n_filters*32,3,batch_norm);\n",
    "# #   c55 = conv_block(p4,n_filters*16,3,batch_norm);\n",
    "\n",
    "#   u66 = Conv3DTranspose(n_filters*16, (3,3,3), strides=(2, 2, 2), padding='same')(c55);\n",
    "#   u66 = concatenate([u66,c5]);  \n",
    "#   c66 = conv_block(u66,n_filters*16,3,batch_norm)\n",
    "#   c66 = Dropout(dropout)(c66)\n",
    "\n",
    "\n",
    "#   u6 = Conv3DTranspose(n_filters*8, (3,3,3), strides=(2, 2, 2), padding='same')(c66);\n",
    "#   u6 = concatenate([u6,c4]);\n",
    "#   c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
    "#   c6 = Dropout(dropout)(c6)\n",
    "#   u7 = Conv3DTranspose(n_filters*4,(3,3,3),strides = (2,2,2) , padding= 'same')(c6);\n",
    "\n",
    "#   u7 = concatenate([u7,c3]);\n",
    "#   c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
    "#   c7 = Dropout(dropout)(c7)\n",
    "#   u8 = Conv3DTranspose(n_filters*2,(3,3,3),strides = (2,2,2) , padding='same')(c7);\n",
    "#   u8 = concatenate([u8,c2]);\n",
    "\n",
    "#   c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
    "#   c8 = Dropout(dropout)(c8)\n",
    "#   u9 = Conv3DTranspose(n_filters,(3,3,3),strides = (2,2,2) , padding='same')(c8);\n",
    "\n",
    "#   u9 = concatenate([u9,c1]);\n",
    "\n",
    "#   c9 = conv_block(u9,n_filters,3,batch_norm)\n",
    "#   outputs = Conv3D(4, (1, 1,1), activation='softmax')(c9)\n",
    "# #   print(outputs.shape)  ==> (None, 128, 128, 128, 4)\n",
    "#   model = Model(inputs=input_img, outputs=outputs)\n",
    "    \n",
    "#   return model\n",
    "\n",
    "def Unet_3d(input_img, n_filters = 8, dropout = 0.2, batch_norm = True):\n",
    "\n",
    "  c1 = conv_block(input_img,n_filters,3,batch_norm)\n",
    "  p1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(c1)\n",
    "  p1 = Dropout(dropout)(p1)\n",
    "  \n",
    "  c2 = conv_block(p1,n_filters*2,3,batch_norm);\n",
    "  p2 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c2)\n",
    "  p2 = Dropout(dropout)(p2)\n",
    "\n",
    "  c3 = conv_block(p2,n_filters*4,3,batch_norm);\n",
    "  p3 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c3)\n",
    "  p3 = Dropout(dropout)(p3)\n",
    "  \n",
    "  c4 = conv_block(p3,n_filters*8,3,batch_norm);\n",
    "  p4 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c4)\n",
    "  p4 = Dropout(dropout)(p4)\n",
    "  \n",
    "  c5 = conv_block(p4,n_filters*16,3,batch_norm);\n",
    "\n",
    "  u6 = Conv3DTranspose(n_filters*8, (3,3,3), strides=(2, 2, 2), padding='same')(c5);\n",
    "  u6 = concatenate([u6,c4]);\n",
    "  c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
    "  c6 = Dropout(dropout)(c6)\n",
    "  u7 = Conv3DTranspose(n_filters*4,(3,3,3),strides = (2,2,2) , padding= 'same')(c6);\n",
    "\n",
    "  u7 = concatenate([u7,c3]);\n",
    "  c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
    "  c7 = Dropout(dropout)(c7)\n",
    "  u8 = Conv3DTranspose(n_filters*2,(3,3,3),strides = (2,2,2) , padding='same')(c7);\n",
    "  u8 = concatenate([u8,c2]);\n",
    "\n",
    "  c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
    "  c8 = Dropout(dropout)(c8)\n",
    "  u9 = Conv3DTranspose(n_filters,(3,3,3),strides = (2,2,2) , padding='same')(c8);\n",
    "\n",
    "  u9 = concatenate([u9,c1]);\n",
    "\n",
    "  c9 = conv_block(u9,n_filters,3,batch_norm)\n",
    "  outputs = Conv3D(4, (1, 1,1), activation='softmax')(c9)\n",
    "  print(\"!!!!!!!!!!!!!!!!!!!\")\n",
    "  print(outputs.shape)\n",
    "  model = Model(inputs=input_img, outputs=outputs)\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "def standardize(image):\n",
    "\n",
    "  standardized_image = np.zeros(image.shape)\n",
    "\n",
    "  for z in range(image.shape[2]):\n",
    "      # get a slice of the image \n",
    "      # at channel c and z-th dimension `z`\n",
    "      image_slice = image[:,:,z]\n",
    "\n",
    "      # subtract the mean from image_slice\n",
    "      centered = image_slice - np.mean(image_slice)\n",
    "      \n",
    "      # divide by the standard deviation (only if it is different from zero)\n",
    "      if(np.std(centered)!=0):\n",
    "          centered = centered/np.std(centered) \n",
    "\n",
    "      # update  the slice of standardized image\n",
    "      # with the scaled centered and scaled image\n",
    "      standardized_image[:, :, z] = centered\n",
    "\n",
    "  ### END CODE HERE ###\n",
    "\n",
    "  return standardized_image\n",
    "\n",
    "\n",
    "# def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "#     \"\"\"\n",
    "#     Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "#          =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "#     ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "#     \"\"\"\n",
    "#     axis = (0,1,2,3)\n",
    "#     dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "#     dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "#     return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:29:50.997687Z",
     "iopub.status.busy": "2023-03-28T13:29:50.996902Z",
     "iopub.status.idle": "2023-03-28T13:29:51.002883Z",
     "shell.execute_reply": "2023-03-28T13:29:51.001668Z",
     "shell.execute_reply.started": "2023-03-28T13:29:50.997646Z"
    }
   },
   "outputs": [],
   "source": [
    "# # CallBacks\n",
    "# import keras\n",
    "# from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "# # Define callback to save model at specific epochs\n",
    "# checkpoint = ModelCheckpoint('model_{epoch:02d}.h5', monitor='val_loss', save_best_only=False, save_weights_only=False, mode='auto', period=1, save_freq='epoch')\n",
    "# epochs_to_save = [10, 20, 30, 40]\n",
    "# class SaveEpochs(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         if epoch + 1 in epochs_to_save:\n",
    "#             self.model.save(f'model_{epoch+1}.h5')\n",
    "\n",
    "# # Define callback to log training history\n",
    "# csv_logger = CSVLogger('training.log')\n",
    "\n",
    "# # callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1),    checkpoint,    SaveEpochs(),    csv_logger]\n",
    "# callbacks = [checkpoint,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:29:51.566422Z",
     "iopub.status.busy": "2023-03-28T13:29:51.564832Z",
     "iopub.status.idle": "2023-03-28T13:29:51.580810Z",
     "shell.execute_reply": "2023-03-28T13:29:51.578493Z",
     "shell.execute_reply.started": "2023-03-28T13:29:51.566370Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the callback to save model checkpoints\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='my_model_checkpoint_{epoch}.h5',\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1),    checkpoint,    SaveEpochs(),    csv_logger]\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1), checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:29:54.655565Z",
     "iopub.status.busy": "2023-03-28T13:29:54.655112Z",
     "iopub.status.idle": "2023-03-28T13:29:54.671519Z",
     "shell.execute_reply": "2023-03-28T13:29:54.670439Z",
     "shell.execute_reply.started": "2023-03-28T13:29:54.655525Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "\n",
    "def imageLoader(path, folders, batch_size=1, Req=None):\n",
    "\n",
    "    L = len(folders)\n",
    "    \n",
    "    data = np.zeros((240,240,155,4))\n",
    "    image_data2=np.zeros((240,240,155))\n",
    "\n",
    "    #keras needs the generator infinite, so we will use while true  \n",
    "    while True:\n",
    "\n",
    "        image_num = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while image_num < L: # 369 images in total\n",
    "            limit = min(batch_end, 369)\n",
    "                \n",
    "            x = folders[image_num]\n",
    "            if(Req):\n",
    "                print(\"Here \"+ Req + \" \" + x)\n",
    "            \n",
    "#             print(x)\n",
    "            \n",
    "            folder_path = path + '/' + x;\n",
    "            modalities = os.listdir(folder_path)\n",
    "            modalities.sort()\n",
    "            \n",
    "            \n",
    "            w = 0\n",
    "            for j in range(len(modalities)):\n",
    "              image_path = folder_path + '/' + modalities[j]\n",
    "              if(image_path[-7:-1] + image_path[-1] == 'seg.nii'):\n",
    "                img = nib.load(image_path);\n",
    "                image_data2 = img.get_fdata()\n",
    "                image_data2 = np.asarray(image_data2)\n",
    "              else:\n",
    "                img = nib.load(image_path);\n",
    "                image_data = img.get_fdata()\n",
    "                image_data = np.asarray(image_data)\n",
    "                image_data = standardize(image_data)\n",
    "                data[:,:,:,w] = image_data\n",
    "                w = w+1\n",
    "            \n",
    "            reshaped_data=data[56:184,80:208,13:141,:]\n",
    "    \n",
    "            reshaped_image_data2=image_data2[56:184,80:208,13:141]\n",
    "        \n",
    "        \n",
    "            reshaped_data=reshaped_data.reshape(1,128,128,128,4)\n",
    "            reshaped_image_data2=reshaped_image_data2.reshape(1,128,128,128)\n",
    "            reshaped_image_data2[reshaped_image_data2==4] = 3\n",
    "            hello = reshaped_image_data2.flatten()\n",
    "            \n",
    "            \n",
    "#             class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(hello),y = hello)\n",
    "\n",
    "            reshaped_image_data2 = to_categorical(reshaped_image_data2, num_classes = 4)\n",
    "            \n",
    "            \n",
    "                       \n",
    "            X = reshaped_data\n",
    "            Y = reshaped_image_data2\n",
    "\n",
    "            yield (X,Y)    \n",
    "\n",
    "            image_num += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:29:56.364764Z",
     "iopub.status.busy": "2023-03-28T13:29:56.364317Z",
     "iopub.status.idle": "2023-03-28T13:29:56.376274Z",
     "shell.execute_reply": "2023-03-28T13:29:56.374910Z",
     "shell.execute_reply.started": "2023-03-28T13:29:56.364724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371\n",
      "['BraTS20_Training_367', 'BraTS20_Training_368', 'BraTS20_Training_369', 'name_mapping.csv', 'survival_info.csv']\n",
      "['BraTS20_Training_355_flair.nii', 'W39_1998.09.19_Segm.nii', 'BraTS20_Training_355_t2.nii', 'BraTS20_Training_355_t1.nii', 'BraTS20_Training_355_t1ce.nii']\n",
      "['BraTS20_Training_365', 'BraTS20_Training_366', 'BraTS20_Training_367', 'BraTS20_Training_368', 'BraTS20_Training_369']\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_images = os.listdir(path)\n",
    "all_images.sort()\n",
    "print(len(all_images))\n",
    "print(all_images[-5:])\n",
    "all_images.remove('name_mapping.csv')\n",
    "all_images.remove('survival_info.csv')\n",
    "\n",
    "print(os.listdir(path+'BraTS20_Training_355'))\n",
    "all_images.remove('BraTS20_Training_355')\n",
    "print(all_images[-5:])\n",
    "\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:30:10.855835Z",
     "iopub.status.busy": "2023-03-28T13:30:10.854653Z",
     "iopub.status.idle": "2023-03-28T13:30:10.865823Z",
     "shell.execute_reply": "2023-03-28T13:30:10.864598Z",
     "shell.execute_reply.started": "2023-03-28T13:30:10.855786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Val Folders: 92\n",
      "Train Folders: 276\n",
      "Test Folders: 46\n",
      "Val Folders: 46\n"
     ]
    }
   ],
   "source": [
    "train_folders, test_val_folders  = train_test_split(all_images, test_size=0.25, random_state=42)\n",
    "\n",
    "val_folders, test_folders = train_test_split(test_val_folders, test_size=0.5, random_state=42)\n",
    "\n",
    "# print the results\n",
    "print('Test_Val Folders:', len(test_val_folders))\n",
    "print('Train Folders:', len(train_folders))\n",
    "print('Test Folders:', len(test_folders))\n",
    "print('Val Folders:', len(val_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:30:21.195457Z",
     "iopub.status.busy": "2023-03-28T13:30:21.194708Z",
     "iopub.status.idle": "2023-03-28T13:30:21.202242Z",
     "shell.execute_reply": "2023-03-28T13:30:21.200892Z",
     "shell.execute_reply.started": "2023-03-28T13:30:21.195416Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "path = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "\n",
    "train_img_datagen = imageLoader(path, train_folders, batch_size)\n",
    "val_img_datagen = imageLoader(path, val_folders, batch_size)\n",
    "test_img_datagen = imageLoader(path, test_folders, batch_size)\n",
    "\n",
    "        \n",
    "# training_generator = DataGenerator(train_folders)\n",
    "# valid_generator = DataGenerator(val_folders)\n",
    "# test_generator = DataGenerator(test_folders)\n",
    "\n",
    "\n",
    "\n",
    "#Verify generator.... In python 3 next() is renamed as __next__()\n",
    "# img, msk = train_img_datagen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:30:22.954813Z",
     "iopub.status.busy": "2023-03-28T13:30:22.953761Z",
     "iopub.status.idle": "2023-03-28T13:30:22.961495Z",
     "shell.execute_reply": "2023-03-28T13:30:22.960165Z",
     "shell.execute_reply.started": "2023-03-28T13:30:22.954765Z"
    }
   },
   "outputs": [],
   "source": [
    "# img, msk = train_img_datagen.__next__()\n",
    "# img.shape\n",
    "# print(img[:,:,:,:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:30:26.355543Z",
     "iopub.status.busy": "2023-03-28T13:30:26.354445Z",
     "iopub.status.idle": "2023-03-28T13:30:26.362619Z",
     "shell.execute_reply": "2023-03-28T13:30:26.361140Z",
     "shell.execute_reply.started": "2023-03-28T13:30:26.355495Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install segmentation-models-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:30:26.365957Z",
     "iopub.status.busy": "2023-03-28T13:30:26.365086Z",
     "iopub.status.idle": "2023-03-28T13:30:26.375159Z",
     "shell.execute_reply": "2023-03-28T13:30:26.374021Z",
     "shell.execute_reply.started": "2023-03-28T13:30:26.365915Z"
    }
   },
   "outputs": [],
   "source": [
    "import segmentation_models_3D as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:42.405620Z",
     "iopub.status.busy": "2023-03-28T13:31:42.405211Z",
     "iopub.status.idle": "2023-03-28T13:31:42.411066Z",
     "shell.execute_reply": "2023-03-28T13:31:42.409633Z",
     "shell.execute_reply.started": "2023-03-28T13:31:42.405561Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory = '/kaggle/working/'\n",
    "\n",
    "# for file_name in os.listdir(directory):\n",
    "#     file_path = os.path.join(directory, file_name)\n",
    "#     if os.path.isfile(file_path):\n",
    "#         os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:31:45.824313Z",
     "iopub.status.busy": "2023-03-28T13:31:45.823878Z",
     "iopub.status.idle": "2023-03-28T13:33:15.871135Z",
     "shell.execute_reply": "2023-03-28T13:33:15.869912Z",
     "shell.execute_reply.started": "2023-03-28T13:31:45.824276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!\n",
      "(None, 128, 128, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((128,128,128,4))\n",
    "model = Unet_3d(input_img)\n",
    "\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5),dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing]\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=dice_coef_loss, metrics=metrics)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:33:15.873976Z",
     "iopub.status.busy": "2023-03-28T13:33:15.873612Z",
     "iopub.status.idle": "2023-03-28T14:00:40.657528Z",
     "shell.execute_reply": "2023-03-28T14:00:40.654121Z",
     "shell.execute_reply.started": "2023-03-28T13:33:15.873941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.9326 - iou_score: 0.4454 - dice_coef: 0.5316 - precision: 0.9711 - sensitivity: 0.8650 - specificity: 0.9924 - dice_coef_necrotic: 0.9652 - dice_coef_edema: 0.9643 - dice_coef_enhancing: 0.9660\n",
      "Epoch 1: saving model to my_model_checkpoint_1.h5\n",
      "276/276 [==============================] - 803s 3s/step - loss: 0.4684 - accuracy: 0.9326 - iou_score: 0.4454 - dice_coef: 0.5316 - precision: 0.9711 - sensitivity: 0.8650 - specificity: 0.9924 - dice_coef_necrotic: 0.9652 - dice_coef_edema: 0.9643 - dice_coef_enhancing: 0.9660 - val_loss: 0.8972 - val_accuracy: 0.2370 - val_iou_score: 0.0580 - val_dice_coef: 0.1028 - val_precision: 0.2341 - val_sensitivity: 0.2176 - val_specificity: 0.7611 - val_dice_coef_necrotic: 0.8786 - val_dice_coef_edema: 0.8158 - val_dice_coef_enhancing: 0.7524 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.9758 - iou_score: 0.5580 - dice_coef: 0.6850 - precision: 0.9793 - sensitivity: 0.9731 - specificity: 0.9931 - dice_coef_necrotic: 0.9991 - dice_coef_edema: 0.9989 - dice_coef_enhancing: 0.9989\n",
      "Epoch 2: saving model to my_model_checkpoint_2.h5\n",
      "276/276 [==============================] - 762s 3s/step - loss: 0.3150 - accuracy: 0.9758 - iou_score: 0.5580 - dice_coef: 0.6850 - precision: 0.9793 - sensitivity: 0.9731 - specificity: 0.9931 - dice_coef_necrotic: 0.9991 - dice_coef_edema: 0.9989 - dice_coef_enhancing: 0.9989 - val_loss: 0.5004 - val_accuracy: 0.9233 - val_iou_score: 0.4017 - val_dice_coef: 0.4996 - val_precision: 0.9312 - val_sensitivity: 0.9167 - val_specificity: 0.9775 - val_dice_coef_necrotic: 0.9984 - val_dice_coef_edema: 0.9971 - val_dice_coef_enhancing: 0.9960 - lr: 0.0010\n",
      "Epoch 3/25\n",
      " 32/276 [==>...........................] - ETA: 9:47 - loss: 0.2945 - accuracy: 0.9782 - iou_score: 0.5683 - dice_coef: 0.7055 - precision: 0.9811 - sensitivity: 0.9759 - specificity: 0.9938 - dice_coef_necrotic: 0.9993 - dice_coef_edema: 0.9993 - dice_coef_enhancing: 0.9995"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/4102042356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_folders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                   callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(train_img_datagen, \n",
    "                  epochs=25, \n",
    "                  steps_per_epoch=(len(train_folders)//batch_size),\n",
    "                  validation_data=val_img_datagen,\n",
    "                  validation_steps=(len(val_folders)//batch_size),\n",
    "                  verbose=1,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T11:47:25.221808Z",
     "iopub.status.busy": "2023-03-28T11:47:25.221310Z",
     "iopub.status.idle": "2023-03-28T11:47:25.227215Z",
     "shell.execute_reply": "2023-03-28T11:47:25.225742Z",
     "shell.execute_reply.started": "2023-03-28T11:47:25.221770Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save('/kaggle/working/3d_unet_model_s1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T12:14:53.517378Z",
     "iopub.status.busy": "2023-03-28T12:14:53.516979Z",
     "iopub.status.idle": "2023-03-28T12:14:54.137944Z",
     "shell.execute_reply": "2023-03-28T12:14:54.136656Z",
     "shell.execute_reply.started": "2023-03-28T12:14:53.517338Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('/kaggle/input/savedmodel2/my_model_checkpoint_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-28T13:03:06.666069Z",
     "iopub.status.busy": "2023-03-28T13:03:06.664050Z",
     "iopub.status.idle": "2023-03-28T13:03:06.729460Z",
     "shell.execute_reply": "2023-03-28T13:03:06.724669Z",
     "shell.execute_reply.started": "2023-03-28T13:03:06.666014Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "generator already executing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24/1917364905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                   \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                   callbacks=[checkpoint_callback])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: generator already executing"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_img_datagen, \n",
    "                  epochs=25, \n",
    "                  steps_per_epoch=(len(train_folders)//batch_size),\n",
    "                  validation_data=val_img_datagen,\n",
    "                  validation_steps=(len(val_folders)//batch_size),\n",
    "                  verbose=1,\n",
    "                  initial_epoch=3,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T14:42:48.213380Z",
     "iopub.status.idle": "2023-03-25T14:42:48.213871Z",
     "shell.execute_reply": "2023-03-25T14:42:48.213640Z",
     "shell.execute_reply.started": "2023-03-25T14:42:48.213616Z"
    }
   },
   "outputs": [],
   "source": [
    "# history.history\n",
    "import pickle\n",
    "\n",
    "# assume history is a dictionary object returned by model.fit()\n",
    "# history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "# save the history object to a file\n",
    "with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.history\n",
    "import pandas as pd\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "print(\"H1\")\n",
    "history_df = pd.DataFrame(history_dict)\n",
    "print(\"H2\")\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "history_df.to_csv('history.csv', index=False)\n",
    "print(\"H3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(test_img_datagen, verbose=1, steps=len(test_folders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all evaluation metrics\n",
    "for name, value in zip(model.metrics_names, test_metrics):\n",
    "    print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictByPath(x):\n",
    "    print(x)\n",
    "    print(\"Results on image number 201\")\n",
    "    folder_path = path + '/' + x;\n",
    "    modalities = os.listdir(folder_path)\n",
    "    modalities.sort()\n",
    "    data = np.zeros((240,240,155,4))\n",
    "    #data = []\n",
    "    w = 0\n",
    "    for j in range(len(modalities)):\n",
    "      #print(modalities[j])\n",
    "\n",
    "      image_path = folder_path + '/' + modalities[j]\n",
    "      if not(image_path.find('seg.nii') == -1):\n",
    "        img = nib.load(image_path);\n",
    "        image_data2 = img.get_fdata()\n",
    "        image_data2 = np.asarray(image_data2)\n",
    "        print(\"Entered ground truth\")\n",
    "      else:\n",
    "        img = nib.load(image_path);\n",
    "        image_data = img.get_fdata()\n",
    "        image_data = np.asarray(image_data)\n",
    "        image_data = standardize(image_data)\n",
    "        data[:,:,:,w] = image_data\n",
    "        print(\"Entered modality\")\n",
    "        w = w+1\n",
    "\n",
    "    print(data.shape)\n",
    "    print(image_data2.shape)  \n",
    "\n",
    "    reshaped_data=data[56:184,75:203,13:141,:]\n",
    "    reshaped_data=reshaped_data.reshape(1,128,128,128,4)\n",
    "    reshaped_image_data2=image_data2[56:184,75:203,13:141]\n",
    "\n",
    "\n",
    "    reshaped_image_data2=reshaped_image_data2.reshape(1,128,128,128)\n",
    "    reshaped_image_data2[reshaped_image_data2==4] = 3\n",
    "    #hello = reshaped_image_data2.flatten()\n",
    "    #y_to = keras.utils.to_categorical(y_to,num_classes=2)\n",
    "    print(reshaped_image_data2.shape)\n",
    "    #print(hello[hello==3].shape)\n",
    "    #print(\"Number of classes\",np.unique(hello))\n",
    "    #class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
    "    #print(class_weights)\n",
    "\n",
    "    #reshaped_image_data2 = keras.utils.to_categorical(reshaped_image_data2, num_classes = 4)\n",
    "\n",
    "    print(reshaped_data.shape)\n",
    "    print(reshaped_image_data2.shape)\n",
    "    print(type(reshaped_data))\n",
    "    \n",
    "    \n",
    "    Y_hat = model.predict(x=reshaped_data)\n",
    "    Y_hat = np.argmax(Y_hat,axis=-1)\n",
    "    print(Y_hat.shape)\n",
    "\n",
    "    slice = 51\n",
    "\n",
    "    img = reshaped_data[0,:,:,slice,0]\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.title('Flair Modality 64th slice')\n",
    "    # plt.savefig('Flair')\n",
    "    plt.show()\n",
    "\n",
    "    img2 = reshaped_image_data2[0,:,:,slice]\n",
    "    imgplot2 = plt.imshow(img2)\n",
    "    plt.title('Ground Truth of 64th slice')\n",
    "    # plt.savefig('Ground_Truth')\n",
    "    plt.show()\n",
    "\n",
    "    img3 = Y_hat[0,:,:,slice]\n",
    "    imgplot3 = plt.imshow(img3)\n",
    "    plt.title('Our Segmentation -> 64th slice')\n",
    "    # plt.savefig('Our Segmentation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_folders\n",
    "\n",
    "for x in X:\n",
    "    predictByPath(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folders[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
