{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T10:42:14.412855Z",
     "iopub.status.busy": "2023-05-05T10:42:14.412256Z",
     "iopub.status.idle": "2023-05-05T10:42:14.433363Z",
     "shell.execute_reply": "2023-05-05T10:42:14.432024Z",
     "shell.execute_reply.started": "2023-05-05T10:42:14.412809Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import metrics\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Maximum, concatenate\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose\n",
    "\n",
    "from keras.layers.pooling import MaxPooling2D,MaxPooling3D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-05T10:32:42.198550Z",
     "iopub.status.busy": "2023-05-05T10:32:42.198106Z",
     "iopub.status.idle": "2023-05-05T10:32:42.237566Z",
     "shell.execute_reply": "2023-05-05T10:32:42.236518Z",
     "shell.execute_reply.started": "2023-05-05T10:32:42.198520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/brats-2021-task1/BraTS2021_00495.tar\n",
      "/kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar\n",
      "/kaggle/input/brats-2021-task1/BraTS2021_00621.tar\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:23:25.472726Z",
     "iopub.status.busy": "2023-05-05T12:23:25.472228Z",
     "iopub.status.idle": "2023-05-05T12:23:25.488583Z",
     "shell.execute_reply": "2023-05-05T12:23:25.487148Z",
     "shell.execute_reply.started": "2023-05-05T12:23:25.472680Z"
    }
   },
   "outputs": [],
   "source": [
    "###Libraries and imports\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "import glob\n",
    "import gc\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import PIL\n",
    "import scipy.misc\n",
    "import skimage\n",
    "import nibabel as nib\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers \n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from skimage.io import imread\n",
    "from scipy import ndimage as ndi\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from glob import glob\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    Conv3D,\n",
    "    Conv3DTranspose,\n",
    "    MaxPooling3D,\n",
    "    UpSampling3D,\n",
    ")\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models, layers, regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T10:37:24.427174Z",
     "iopub.status.busy": "2023-05-05T10:37:24.426347Z",
     "iopub.status.idle": "2023-05-05T10:39:39.064092Z",
     "shell.execute_reply": "2023-05-05T10:39:39.062993Z",
     "shell.execute_reply.started": "2023-05-05T10:37:24.427134Z"
    }
   },
   "outputs": [],
   "source": [
    "# open the tar file for reading\n",
    "tar = tarfile.open('/kaggle/input/brats-2021-task1/BraTS2021_Training_Data.tar', 'r')\n",
    "\n",
    "# extract all files and directories\n",
    "tar.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T10:42:24.586098Z",
     "iopub.status.busy": "2023-05-05T10:42:24.585677Z",
     "iopub.status.idle": "2023-05-05T10:42:24.605389Z",
     "shell.execute_reply": "2023-05-05T10:42:24.604204Z",
     "shell.execute_reply.started": "2023-05-05T10:42:24.586064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251\n",
      "Directories in BraTS2021_Training_Data.tar (sorted):\n",
      "BraTS2021_00000\n",
      "BraTS2021_00002\n",
      "BraTS2021_00003\n",
      "BraTS2021_00005\n",
      "BraTS2021_00006\n"
     ]
    }
   ],
   "source": [
    "# get a list of all directories in the current folder\n",
    "directories = [name for name in os.listdir() if os.path.isdir('/kaggle/working/')]\n",
    "\n",
    "nums = [str(x.split('_')[1]) for x in directories]\n",
    "\n",
    "directories.remove('__notebook_source__.ipynb')\n",
    "directories.remove('.virtual_documents')\n",
    "directories.remove('.DS_Store')\n",
    "\n",
    "for i in directories:\n",
    "    y = i.split('_')[1]\n",
    "    if len(y)<5 :\n",
    "        print(\"Here: \",i)\n",
    "\n",
    "# sort the directories based on the number in the name\n",
    "# sorted_directories = sorted(directories, key=lambda x: int(x.split('_')[1]) if x.split('_')[1].isdigit() else float('inf'))\n",
    "\n",
    "sorted_directories = sorted(directories, key=lambda x: int(x.split('_')[1]))\n",
    "\n",
    "print(len(sorted_directories))\n",
    "# print the sorted list of directories\n",
    "print(\"Directories in BraTS2021_Training_Data.tar (sorted):\")\n",
    "for directory in sorted_directories[:5]:\n",
    "    print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:48.413722Z",
     "iopub.status.busy": "2023-05-05T12:26:48.412752Z",
     "iopub.status.idle": "2023-05-05T12:26:48.433407Z",
     "shell.execute_reply": "2023-05-05T12:26:48.431688Z",
     "shell.execute_reply.started": "2023-05-05T12:26:48.413683Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "      =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    axis = (0,1,2,3)\n",
    "    dice_numerator = 2. * K.sum(K.abs(y_true * y_pred), axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "#     return 2*(dice_numerator)/(dice_denominator)\n",
    "\n",
    "\n",
    "# def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "#     A = y_true\n",
    "#     B = y_pred\n",
    "    \n",
    "#     smooth = 1e-7\n",
    "    \n",
    "#     intersection = np.sum(A * B, axis=(0,1,2,3))\n",
    "#     sum_A = np.sum(A, axis=(0,1,2,3))\n",
    "#     sum_B = np.sum(B, axis=(0,1,2,3))\n",
    "    \n",
    "#     dice = (2. * intersection + smooth) / (sum_A + sum_B + smooth)\n",
    "    \n",
    "#     return dice\n",
    "\n",
    "\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=0.000001): ## NON-ENHANCING tumor CORE\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=0.000001):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=0.000001):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision\n",
    "# Precision: TP / (TP + FP)\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity  \n",
    "# Sensitivity or recall: TP / (TP + FN)\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "# Specificity: TN / (TN + FP)\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:54.369307Z",
     "iopub.status.busy": "2023-05-05T12:26:54.368286Z",
     "iopub.status.idle": "2023-05-05T12:26:54.387627Z",
     "shell.execute_reply": "2023-05-05T12:26:54.386459Z",
     "shell.execute_reply.started": "2023-05-05T12:26:54.369236Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(input_mat,num_filters,kernel_size,batch_norm):\n",
    "  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(input_mat)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    "  \n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(X)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    "  \n",
    "  X = Activation('relu')(X)\n",
    "  \n",
    "  return X\n",
    "\n",
    "\n",
    "def Unet_3d(input_img, n_filters = 16, dropout = 0.2, batch_norm = True):\n",
    "\n",
    "  c1 = conv_block(input_img,n_filters,3,batch_norm)\n",
    "  p1 = MaxPooling3D(pool_size=(2, 2, 2), strides=2)(c1)\n",
    "  p1 = Dropout(dropout)(p1)\n",
    "  \n",
    "  c2 = conv_block(p1,n_filters*2,3,batch_norm);\n",
    "  p2 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c2)\n",
    "  p2 = Dropout(dropout)(p2)\n",
    "\n",
    "  c3 = conv_block(p2,n_filters*4,3,batch_norm);\n",
    "  p3 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c3)\n",
    "  p3 = Dropout(dropout)(p3)\n",
    "  \n",
    "  c4 = conv_block(p3,n_filters*8,3,batch_norm);\n",
    "  p4 = MaxPooling3D(pool_size=(2,2,2) ,strides=2)(c4)\n",
    "  p4 = Dropout(dropout)(p4)\n",
    "  \n",
    "  c5 = conv_block(p4,n_filters*16,3,batch_norm);\n",
    "\n",
    "  u6 = Conv3DTranspose(n_filters*8, (3,3,3), strides=(2, 2, 2), padding='same')(c5);\n",
    "  u6 = concatenate([u6,c4]);\n",
    "  c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
    "  c6 = Dropout(dropout)(c6)\n",
    "  u7 = Conv3DTranspose(n_filters*4,(3,3,3),strides = (2,2,2) , padding= 'same')(c6);\n",
    "\n",
    "  u7 = concatenate([u7,c3]);\n",
    "  c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
    "  c7 = Dropout(dropout)(c7)\n",
    "  u8 = Conv3DTranspose(n_filters*2,(3,3,3),strides = (2,2,2) , padding='same')(c7);\n",
    "  u8 = concatenate([u8,c2]);\n",
    "\n",
    "  c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
    "  c8 = Dropout(dropout)(c8)\n",
    "  u9 = Conv3DTranspose(n_filters,(3,3,3),strides = (2,2,2) , padding='same')(c8);\n",
    "\n",
    "  u9 = concatenate([u9,c1]);\n",
    "\n",
    "  c9 = conv_block(u9,n_filters,3,batch_norm)\n",
    "  outputs = Conv3D(4, (1, 1,1), activation='softmax')(c9)\n",
    "\n",
    "  model = Model(inputs=input_img, outputs=outputs)\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "def standardize(img_data):\n",
    "    mean = np.mean(img_data)\n",
    "    std = np.std(img_data)\n",
    "    return (img_data - mean) / std\n",
    "\n",
    "#     standardized_image = np.zeros(image.shape)\n",
    "#     for z in range(image.shape[2]):\n",
    "#         image_slice = image[:,:,z]\n",
    "\n",
    "#         # subtract the mean from image_slice\n",
    "#         centered = image_slice - np.mean(image_slice)\n",
    "\n",
    "#         # divide by the standard deviation (only if it is different from zero)\n",
    "#         if(np.std(centered)!=0):\n",
    "#           centered = centered/np.std(centered) \n",
    "\n",
    "#         # update  the slice of standardized image\n",
    "#         # with the scaled centered and scaled image\n",
    "#         standardized_image[:, :, z] = centered\n",
    "#     return standardized_image\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:54.924597Z",
     "iopub.status.busy": "2023-05-05T12:26:54.923421Z",
     "iopub.status.idle": "2023-05-05T12:26:54.930951Z",
     "shell.execute_reply": "2023-05-05T12:26:54.929792Z",
     "shell.execute_reply.started": "2023-05-05T12:26:54.924544Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the callback to save model checkpoints\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='my_model_checkpoint_{epoch}.h5',\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1),    checkpoint,    SaveEpochs(),    csv_logger]\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001, verbose=1), checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:55.508461Z",
     "iopub.status.busy": "2023-05-05T12:26:55.507428Z",
     "iopub.status.idle": "2023-05-05T12:26:55.521979Z",
     "shell.execute_reply": "2023-05-05T12:26:55.520653Z",
     "shell.execute_reply.started": "2023-05-05T12:26:55.508419Z"
    }
   },
   "outputs": [],
   "source": [
    "# path = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "path = '/kaggle/working/'\n",
    "\n",
    "def imageLoader(path, folders, batch_size=1, Req=None):\n",
    "\n",
    "    L = len(folders)\n",
    "    \n",
    "    data = np.zeros((240,240,155,4))\n",
    "    image_data2=np.zeros((240,240,155))\n",
    "\n",
    "    #keras needs the generator infinite, so we will use while true  \n",
    "    while True:\n",
    "\n",
    "        image_num = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while image_num < L: # 369 images in total\n",
    "            limit = min(batch_end, 1251)\n",
    "                \n",
    "            x = folders[image_num]\n",
    "#             if(Req):\n",
    "#                 print(\"Here \"+ Req + \" \" + x)\n",
    "            \n",
    "            folder_path = path + '/' + x;\n",
    "            modalities = os.listdir(folder_path)\n",
    "            modalities.sort()\n",
    "            \n",
    "#             print(x)\n",
    "#             print(modalities)\n",
    "            \n",
    "            \n",
    "            w = 0\n",
    "#             BraTS2021_00618_flair.nii.gz', 'BraTS2021_00618_seg.nii.gz', 'BraTS2021_00618_t1.nii.gz', 'BraTS2021_00618_t1ce.nii.gz', 'BraTS2021_00618_t2.nii.gz\n",
    "            \n",
    "            for j in range(len(modalities)):\n",
    "              image_path = folder_path + '/' + modalities[j]\n",
    "#               print(image_path[-10:-1] + image_path[-1])\n",
    "              if(image_path[-10:-1] + image_path[-1] == 'seg.nii.gz'):\n",
    "                img = nib.load(image_path);\n",
    "                image_data2 = img.get_fdata()\n",
    "                image_data2 = np.asarray(image_data2)\n",
    "              else:\n",
    "                img = nib.load(image_path);\n",
    "                image_data = img.get_fdata()\n",
    "#                 print(\"1: \",np.unique(image_data))\n",
    "                image_data = np.asarray(image_data)\n",
    "#                 print(\"2: \",np.unique(image_data))\n",
    "                image_data = standardize(image_data)\n",
    "#                 print(\"3: \",np.unique(image_data))\n",
    "                data[:,:,:,w] = image_data\n",
    "                w = w+1\n",
    "            \n",
    "            reshaped_data=data[56:184,80:208,13:141,:]\n",
    "    \n",
    "            reshaped_image_data2=image_data2[56:184,80:208,13:141]\n",
    "        \n",
    "        \n",
    "            reshaped_data=reshaped_data.reshape(1,128,128,128,4)\n",
    "            reshaped_image_data2=reshaped_image_data2.reshape(1,128,128,128)\n",
    "            reshaped_image_data2[reshaped_image_data2==4] = 3\n",
    "            hello = reshaped_image_data2.flatten()\n",
    "            \n",
    "            \n",
    "#             class_weights = class_weight.compute_class_weight('balanced',classes = np.unique(hello),y = hello)\n",
    "\n",
    "            reshaped_image_data2 = to_categorical(reshaped_image_data2, num_classes = 4)\n",
    "            \n",
    "            \n",
    "                       \n",
    "            X = reshaped_data\n",
    "            Y = reshaped_image_data2\n",
    "\n",
    "            yield (X,Y)    \n",
    "\n",
    "            image_num += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:55.839370Z",
     "iopub.status.busy": "2023-05-05T12:26:55.838643Z",
     "iopub.status.idle": "2023-05-05T12:26:55.845272Z",
     "shell.execute_reply": "2023-05-05T12:26:55.843996Z",
     "shell.execute_reply.started": "2023-05-05T12:26:55.839330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BraTS2021_01662', 'BraTS2021_01663', 'BraTS2021_01664', 'BraTS2021_01665', 'BraTS2021_01666']\n",
      "1251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(sorted_directories[-5:])\n",
    "\n",
    "print(len(sorted_directories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:56.374496Z",
     "iopub.status.busy": "2023-05-05T12:26:56.373507Z",
     "iopub.status.idle": "2023-05-05T12:26:56.619659Z",
     "shell.execute_reply": "2023-05-05T12:26:56.618201Z",
     "shell.execute_reply.started": "2023-05-05T12:26:56.374432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the NIfTI file\n",
    "img = nib.load('/kaggle/working/BraTS2021_00801/BraTS2021_00801_t1.nii.gz')\n",
    "\n",
    "# Get the first volume of the image data (assuming 4D data)\n",
    "data = img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:57.806392Z",
     "iopub.status.busy": "2023-05-05T12:26:57.806013Z",
     "iopub.status.idle": "2023-05-05T12:26:57.814219Z",
     "shell.execute_reply": "2023-05-05T12:26:57.812985Z",
     "shell.execute_reply.started": "2023-05-05T12:26:57.806359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 155)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:26:58.861859Z",
     "iopub.status.busy": "2023-05-05T12:26:58.860899Z",
     "iopub.status.idle": "2023-05-05T12:26:58.870196Z",
     "shell.execute_reply": "2023-05-05T12:26:58.868923Z",
     "shell.execute_reply.started": "2023-05-05T12:26:58.861819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Folders: 938\n",
      "Test Folders: 313\n"
     ]
    }
   ],
   "source": [
    "train_folders, test_folders  = train_test_split(sorted_directories, test_size=0.25, random_state=42)\n",
    "\n",
    "# val_folders, test_folders = train_test_split(test_val_folders, test_size=0.5, random_state=42)\n",
    "\n",
    "# print the results\n",
    "# print('Test_Val Folders:', len(test_val_folders))\n",
    "print('Train Folders:', len(train_folders))\n",
    "print('Test Folders:', len(test_folders))\n",
    "# print('Val Folders:', len(val_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:00.334250Z",
     "iopub.status.busy": "2023-05-05T12:27:00.333868Z",
     "iopub.status.idle": "2023-05-05T12:27:00.339912Z",
     "shell.execute_reply": "2023-05-05T12:27:00.338550Z",
     "shell.execute_reply.started": "2023-05-05T12:27:00.334217Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "path = '/kaggle/working/'\n",
    "\n",
    "# train_img_datagen = imageLoader(path, train_folders, batch_size)\n",
    "# val_img_datagen = imageLoader(path, val_folders, batch_size)\n",
    "# test_img_datagen = imageLoader(path, test_folders, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:00.795937Z",
     "iopub.status.busy": "2023-05-05T12:27:00.795175Z",
     "iopub.status.idle": "2023-05-05T12:27:00.803727Z",
     "shell.execute_reply": "2023-05-05T12:27:00.802503Z",
     "shell.execute_reply.started": "2023-05-05T12:27:00.795896Z"
    }
   },
   "outputs": [],
   "source": [
    "# X,y = train_img_datagen.__next__()\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:01.648308Z",
     "iopub.status.busy": "2023-05-05T12:27:01.647005Z",
     "iopub.status.idle": "2023-05-05T12:27:01.654072Z",
     "shell.execute_reply": "2023-05-05T12:27:01.652657Z",
     "shell.execute_reply.started": "2023-05-05T12:27:01.648258Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install segmentation-models-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:02.126021Z",
     "iopub.status.busy": "2023-05-05T12:27:02.125645Z",
     "iopub.status.idle": "2023-05-05T12:27:02.131996Z",
     "shell.execute_reply": "2023-05-05T12:27:02.130719Z",
     "shell.execute_reply.started": "2023-05-05T12:27:02.125989Z"
    }
   },
   "outputs": [],
   "source": [
    "import segmentation_models_3D as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:47.643596Z",
     "iopub.status.busy": "2023-05-05T12:27:47.642411Z",
     "iopub.status.idle": "2023-05-05T12:27:47.650573Z",
     "shell.execute_reply": "2023-05-05T12:27:47.649289Z",
     "shell.execute_reply.started": "2023-05-05T12:27:47.643541Z"
    }
   },
   "outputs": [],
   "source": [
    "def combined_loss(y_true, y_pred, alpha=0.5):\n",
    "    # Compute the DC loss\n",
    "    dc_loss = dice_coef_loss(y_true, y_pred)\n",
    "#     print(dc_loss)\n",
    "    \n",
    "    # Compute the binary cross-entropy (BCE) loss\n",
    "#     bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    bce = K.categorical_crossentropy(y_true, y_pred)\n",
    "    bce_loss = K.mean(bce, axis=(1, 2, 3))\n",
    "#     print(bce_loss)\n",
    "    \n",
    "    # Combine the MSE and BCE losses with a weighting factor\n",
    "    combined_loss = alpha * dc_loss + (1 - alpha) * bce_loss\n",
    "    \n",
    "    return combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:48.096058Z",
     "iopub.status.busy": "2023-05-05T12:27:48.095683Z",
     "iopub.status.idle": "2023-05-05T12:27:48.637255Z",
     "shell.execute_reply": "2023-05-05T12:27:48.636231Z",
     "shell.execute_reply.started": "2023-05-05T12:27:48.096024Z"
    }
   },
   "outputs": [],
   "source": [
    "input_img = Input((128,128,128,4))\n",
    "model = Unet_3d(input_img)\n",
    "\n",
    "\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5),dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing]\n",
    "model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001, decay=0.0001), loss=combined_loss, metrics=metrics)\n",
    "# optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001, decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:48.800296Z",
     "iopub.status.busy": "2023-05-05T12:27:48.799596Z",
     "iopub.status.idle": "2023-05-05T12:27:48.807153Z",
     "shell.execute_reply": "2023-05-05T12:27:48.805933Z",
     "shell.execute_reply.started": "2023-05-05T12:27:48.800249Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:49.552182Z",
     "iopub.status.busy": "2023-05-05T12:27:49.550992Z",
     "iopub.status.idle": "2023-05-05T12:27:49.559727Z",
     "shell.execute_reply": "2023-05-05T12:27:49.558803Z",
     "shell.execute_reply.started": "2023-05-05T12:27:49.552133Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:50.503943Z",
     "iopub.status.busy": "2023-05-05T12:27:50.502918Z",
     "iopub.status.idle": "2023-05-05T12:27:50.508741Z",
     "shell.execute_reply": "2023-05-05T12:27:50.507495Z",
     "shell.execute_reply.started": "2023-05-05T12:27:50.503902Z"
    }
   },
   "outputs": [],
   "source": [
    "lyst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T12:27:52.084886Z",
     "iopub.status.busy": "2023-05-05T12:27:52.084152Z",
     "iopub.status.idle": "2023-05-05T13:58:41.931957Z",
     "shell.execute_reply": "2023-05-05T13:58:41.921551Z",
     "shell.execute_reply.started": "2023-05-05T12:27:52.084849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9649 - iou_score: 0.5830 - dice_coef: 0.6838 - precision: 0.9716 - sensitivity: 0.9329 - specificity: 0.9944 - dice_coef_necrotic: 0.9536 - dice_coef_edema: 0.9531 - dice_coef_enhancing: 0.9526\n",
      "Epoch 1: saving model to my_model_checkpoint_1.h5\n",
      "938/938 [==============================] - 1496s 2s/step - loss: 0.2484 - accuracy: 0.9649 - iou_score: 0.5830 - dice_coef: 0.6838 - precision: 0.9716 - sensitivity: 0.9329 - specificity: 0.9944 - dice_coef_necrotic: 0.9536 - dice_coef_edema: 0.9531 - dice_coef_enhancing: 0.9526 - val_loss: 0.2809 - val_accuracy: 0.9721 - val_iou_score: 0.4614 - val_dice_coef: 0.5608 - val_precision: 0.9729 - val_sensitivity: 0.9715 - val_specificity: 0.9910 - val_dice_coef_necrotic: 0.9992 - val_dice_coef_edema: 0.9990 - val_dice_coef_enhancing: 0.9990 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9853 - iou_score: 0.6778 - dice_coef: 0.7936 - precision: 0.9868 - sensitivity: 0.9842 - specificity: 0.9956 - dice_coef_necrotic: 0.9998 - dice_coef_edema: 0.9998 - dice_coef_enhancing: 0.9997\n",
      "Epoch 2: saving model to my_model_checkpoint_2.h5\n",
      "938/938 [==============================] - 1503s 2s/step - loss: 0.1277 - accuracy: 0.9853 - iou_score: 0.6778 - dice_coef: 0.7936 - precision: 0.9868 - sensitivity: 0.9842 - specificity: 0.9956 - dice_coef_necrotic: 0.9998 - dice_coef_edema: 0.9998 - dice_coef_enhancing: 0.9997 - val_loss: 0.1835 - val_accuracy: 0.9738 - val_iou_score: 0.6024 - val_dice_coef: 0.7142 - val_precision: 0.9745 - val_sensitivity: 0.9733 - val_specificity: 0.9915 - val_dice_coef_necrotic: 0.9996 - val_dice_coef_edema: 0.9993 - val_dice_coef_enhancing: 0.9988 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9870 - iou_score: 0.7098 - dice_coef: 0.8171 - precision: 0.9881 - sensitivity: 0.9861 - specificity: 0.9961 - dice_coef_necrotic: 0.9999 - dice_coef_edema: 0.9998 - dice_coef_enhancing: 0.9998\n",
      "Epoch 3: saving model to my_model_checkpoint_3.h5\n",
      "938/938 [==============================] - 1506s 2s/step - loss: 0.1124 - accuracy: 0.9870 - iou_score: 0.7098 - dice_coef: 0.8171 - precision: 0.9881 - sensitivity: 0.9861 - specificity: 0.9961 - dice_coef_necrotic: 0.9999 - dice_coef_edema: 0.9998 - dice_coef_enhancing: 0.9998 - val_loss: 0.2021 - val_accuracy: 0.9803 - val_iou_score: 0.5599 - val_dice_coef: 0.6695 - val_precision: 0.9817 - val_sensitivity: 0.9792 - val_specificity: 0.9939 - val_dice_coef_necrotic: 0.9995 - val_dice_coef_edema: 0.9995 - val_dice_coef_enhancing: 0.9996 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "680/938 [====================>.........] - ETA: 5:57 - loss: 0.1005 - accuracy: 0.9885 - iou_score: 0.7332 - dice_coef: 0.8354 - precision: 0.9895 - sensitivity: 0.9878 - specificity: 0.9965 - dice_coef_necrotic: 0.9999 - dice_coef_edema: 0.9999 - dice_coef_enhancing: 0.9999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/1943099734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_folders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                   callbacks=callbacks)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_folders)):\n",
    "    print('Fold:', fold)\n",
    "    batch_size = 1\n",
    "#     print(train_indices, val_indices)\n",
    "    \n",
    "#     print(max(train_indices),max(val_indices))\n",
    "\n",
    "    train_data = [sorted_directories[x] for x in train_indices]\n",
    "    val_data = [sorted_directories[x] for x in val_indices]\n",
    "    \n",
    "#     print(len(train_data))\n",
    "#     print(len(val_data))\n",
    "    \n",
    "    train_img_datagen = imageLoader(path, train_data, batch_size)\n",
    "    val_img_datagen = imageLoader(path, val_data, batch_size)\n",
    "\n",
    "#     model.fit(train_data, epochs=10, validation_data=val_data)\n",
    "    model.fit(train_img_datagen, \n",
    "                  epochs=10, \n",
    "                  steps_per_epoch=(len(train_folders)//batch_size),\n",
    "                  validation_data=val_img_datagen,\n",
    "                  validation_steps=(len(val_folders)//batch_size),\n",
    "                  verbose=1,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "    scores = model.evaluate(val_data)\n",
    "    lyst.append(scores)\n",
    "    print('Validation accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T11:44:47.435797Z",
     "iopub.status.busy": "2023-05-05T11:44:47.435410Z",
     "iopub.status.idle": "2023-05-05T11:50:50.078991Z",
     "shell.execute_reply": "2023-05-05T11:50:50.076420Z",
     "shell.execute_reply.started": "2023-05-05T11:44:47.435766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "269/938 [=======>......................] - ETA: 14:48 - loss: 0.0305 - accuracy: 0.9604 - iou_score: 0.5148 - dice_coef: 1.2039 - precision: 0.9703 - sensitivity: 0.9264 - specificity: 0.9923 - dice_coef_necrotic: 0.9645 - dice_coef_edema: 0.9627 - dice_coef_enhancing: 0.9625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/359449253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_folders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                   callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(train_img_datagen, \n",
    "                  epochs=20, \n",
    "                  steps_per_epoch=(len(train_folders)//batch_size),\n",
    "                  validation_data=val_img_datagen,\n",
    "                  validation_steps=(len(val_folders)//batch_size),\n",
    "                  verbose=1,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
